import json
import re
import copy
import time
from typing import Dict, List, Any, Tuple, Optional
import math
from openai import OpenAI
from negotiation_logger import NegotiationLogger
from llm_interaction_logger import get_logger

# è®¾ç½®DeepSeekå®¢æˆ·ç«¯
client = OpenAI(
    api_key="",  # æ›¿æ¢ä¸ºä½ çš„DeepSeek APIå¯†é’¥
    base_url=""  # æ ‡å‡†æ ¹è·¯å¾„ï¼Œé¿å… /chat/completions é‡å¤
)

class CollaborativeNegotiation:
    """åä½œå¼åå•†åˆ†é…æœºåˆ¶"""
    
    def __init__(self, agents: List[Dict[str, Any]], total_resources: Dict[str, float], 
                 survival_needs: Dict[int, Dict[str, float]], round_number: int = 1,
                 enable_logging: bool = True, log_dir: str = "negotiation_logs",
                 experiment_id: str = None):
        """åˆå§‹åŒ–åå•†æœºåˆ¶
        
        å‚æ•°:
            agents: ä»£ç†åˆ—è¡¨
            total_resources: æ€»èµ„æºå­—å…¸
            survival_needs: ç”Ÿå­˜éœ€æ±‚å­—å…¸
            round_number: å½“å‰è½®æ•°
            enable_logging: æ˜¯å¦å¯ç”¨æ—¥å¿—è®°å½•
            experiment_id: å®éªŒIDï¼Œç”¨äºç»Ÿä¸€æ‰€æœ‰è½®æ¬¡çš„æ—¥å¿—
        """
        self.agents = agents
        self.total_resources = total_resources
        self.survival_needs = survival_needs
        self.round_number = round_number
        
        # åå•†çŠ¶æ€
        self.current_proposal = self._initialize_empty_proposal()
        self.conversation_history = []
        self.consensus_items = []  # å·²è¾¾æˆå…±è¯†çš„åˆ†é…é¡¹
        self.disputed_items = []   # ä»æœ‰äº‰è®®çš„é¡¹ç›®
        
        # åå•†é˜¶æ®µ
        self.current_stage = "principles"  # principles -> framework -> details -> finalization
        self.stage_results = {}
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.total_grain = total_resources.get("grain", 0)
        self.total_members = sum(agent["members"] for agent in agents)
        self.total_labor = sum(agent["labor_force"] for agent in agents)
        
        # æ—¥å¿—è®°å½•
        self.enable_logging = enable_logging
        if enable_logging:
            # ğŸ†• ä½¿ç”¨experiment_idä½œä¸ºsession_idï¼Œæ‰€æœ‰è½®æ¬¡å…±äº«åŒä¸€ä¸ªæ—¥å¿—ç›®å½•
            if experiment_id:
                session_id = experiment_id
            else:
                import time
                session_id = f"round_{round_number}_{int(time.time())}"
            
            self.logger = NegotiationLogger(session_id, output_dir=log_dir)
            self.logger.start_session(
                round_number=round_number,
                participants=agents,
                total_resources=total_resources,
                survival_needs=survival_needs
            )
        else:
            self.logger = None
    
    def _initialize_empty_proposal(self) -> Dict[int, Dict[str, float]]:
        """åˆå§‹åŒ–ç©ºçš„åˆ†é…ææ¡ˆ"""
        return {agent["id"]: {"grain": 0.0} for agent in self.agents}
    
    def run_collaborative_negotiation(self) -> Tuple[Dict[int, Dict[str, float]], Dict[str, Any]]:
        """è¿è¡Œå®Œæ•´çš„åä½œå¼åå•†æµç¨‹
        
        è¿”å›:
            (æœ€ç»ˆåˆ†é…ç»“æœ, åå•†è¿‡ç¨‹æ•°æ®)
        """
        print("\n" + "="*70)
        print("å¼€å§‹åä½œå¼åå•†åˆ†é…æµç¨‹")
        print("="*70)
        
        try:
            # é˜¶æ®µ1ï¼šç¡®å®šåˆ†é…åŸåˆ™
            print("\n é˜¶æ®µ1ï¼šç¡®å®šåˆ†é…åŸåˆ™")
            principles = self._establish_principles()
            self.stage_results["principles"] = principles
            
            # é˜¶æ®µ2ï¼šåå•†åˆ†é…æ¡†æ¶
            print("\n é˜¶æ®µ2ï¼šåå•†åˆ†é…æ¡†æ¶")
            framework = self._negotiate_framework(principles)
            self.stage_results["framework"] = framework
            
            # é˜¶æ®µ3ï¼šæ„å»ºè¯¦ç»†æ–¹æ¡ˆ
            print("\n é˜¶æ®µ3ï¼šæ„å»ºè¯¦ç»†åˆ†é…æ–¹æ¡ˆ")
            detailed_proposal = self._build_detailed_proposal(framework)
            self.stage_results["detailed_proposal"] = detailed_proposal
            
            # é˜¶æ®µ4ï¼šæœ€ç»ˆç¡®è®¤å’Œè°ƒæ•´
            print("\n é˜¶æ®µ4ï¼šæœ€ç»ˆç¡®è®¤å’Œå¾®è°ƒ")
            final_proposal = self._finalize_proposal(detailed_proposal)
            
            # ç”Ÿæˆåå•†æ•°æ®
            negotiation_data = self._create_negotiation_data(True, "collaborative_consensus")
            
            # ä¼šè¯æ”¶å°¾æ—¥å¿—
            if self.logger:
                avg_satisfaction = getattr(self, "final_average_satisfaction", 0.0)
                try:
                    self.logger.end_session(
                        final_allocation=final_proposal,
                        success=True,
                        average_satisfaction=avg_satisfaction
                    )
                except Exception:
                    pass
            
            print("\n åå•†æˆåŠŸå®Œæˆï¼")
            return final_proposal, negotiation_data
            
        except Exception as e:
            print(f"\n åå•†è¿‡ç¨‹å‡ºç°é”™è¯¯: {str(e)}")
            # å›é€€åˆ°ç®€å•åˆ†é…
            fallback_proposal = self._create_fallback_proposal()
            negotiation_data = self._create_negotiation_data(False, "error_fallback")
            
            # ä¼šè¯æ”¶å°¾æ—¥å¿—ï¼ˆå¤±è´¥ï¼‰
            if self.logger:
                try:
                    self.logger.end_session(
                        final_allocation=fallback_proposal,
                        success=False,
                        failure_reason=str(e),
                        average_satisfaction=0.0
                    )
                except Exception:
                    pass
            return fallback_proposal, negotiation_data
    
    def _establish_principles(self) -> Dict[str, Any]:
        """é˜¶æ®µ1ï¼šç¡®å®šåˆ†é…åŸåˆ™"""
        self.current_stage = "principles"
        
        # å¼€å§‹æ—¥å¿—è®°å½•
        if self.logger:
            self.logger.start_stage("establish_principles", [agent["id"] for agent in self.agents])
        
        # 1.1 æ”¶é›†å„å®¶åº­çš„åŸåˆ™åå¥½
        print("\n   æ”¶é›†å„å®¶åº­çš„åˆ†é…åŸåˆ™åå¥½...")
        principle_preferences = {}
        
        for agent in self.agents:
            preference = self._get_principle_preference(agent)
            principle_preferences[agent["id"]] = preference
            print(f"    {agent['family_name']}å®¶ï¼š{preference['summary']}")
            
            # è®°å½•åŸåˆ™åå¥½
            if self.logger:
                self.logger.log_discussion_turn(
                    speaker_id=agent["id"],
                    speaker_name=agent["family_name"],
                    speaker_value_type=agent["value_type"],
                    content=preference["raw_response"],
                    speech_type="principle_preference",
                    target_topic="åˆ†é…åŸåˆ™åå¥½"
                )
        
        # 1.2 è¯†åˆ«å…±åŒåŸåˆ™
        print("\n   å¯»æ‰¾å…±åŒåŸåˆ™...")
        common_principles = self._find_common_principles(principle_preferences)
        
        # è®°å½•å…±åŒåŸåˆ™å†³ç­–
        if self.logger and common_principles:
            self.logger.log_decision(
                decision_type="common_principles_identified",
                decision_content=common_principles,
                supporters=list(range(1, len(self.agents) + 1)),  # æ‰€æœ‰äººæ”¯æŒçš„åŸåˆ™
                opponents=[]
            )
        
        # 1.3 è®¨è®ºæœ‰äº‰è®®çš„åŸåˆ™
        print("\n   è®¨è®ºæœ‰äº‰è®®çš„åŸåˆ™...")
        discussed_principles = self._discuss_disputed_principles(principle_preferences, common_principles)
        
        # 1.4 ç¡®å®šæœ€ç»ˆåŸåˆ™
        final_principles = {**common_principles, **discussed_principles}
        
        print(f"\n   ç¡®å®šçš„åˆ†é…åŸåˆ™ï¼š")
        for key, value in final_principles.items():
            print(f"    - {key}: {value}")
        
        # ç»“æŸé˜¶æ®µè®°å½•
        if self.logger:
            consensus_level = len(final_principles) / max(len(principle_preferences), 1)
            self.logger.end_stage(
                stage_outcome=f"ç¡®å®šäº†{len(final_principles)}ä¸ªåˆ†é…åŸåˆ™",
                consensus_level=consensus_level
            )
        
        return final_principles
    
    def _get_principle_preference(self, agent: Dict[str, Any]) -> Dict[str, Any]:
        """è·å–ä»£ç†çš„åŸåˆ™åå¥½"""
        prompt = f"""ä½ æ˜¯{agent['family_name']}å®¶åº­çš„ä»£è¡¨ï¼Œä»·å€¼è§‚ä¸º{agent['value_type']}ã€‚

å®¶åº­æƒ…å†µï¼š
- æˆå‘˜æ•°ï¼š{agent['members']}äºº
- åŠ³åŠ¨åŠ›ï¼š{agent['labor_force']}äºº
- æ ¸å¿ƒä¿¡å¿µï¼š{agent['core_beliefs'][0]}

ç¤¾åŒºæƒ…å†µï¼š
- æ€»èµ„æºï¼š{self.total_grain:.1f}å•ä½å†œä½œç‰©
- æ€»äººå£ï¼š{self.total_members}äºº
- æ€»åŠ³åŠ¨åŠ›ï¼š{self.total_labor}äºº

ç°åœ¨ç¤¾åŒºéœ€è¦ç¡®å®šèµ„æºåˆ†é…çš„åŸºæœ¬åŸåˆ™ã€‚è¯·è¡¨è¾¾ä½ è®¤ä¸ºæœ€é‡è¦çš„3ä¸ªåˆ†é…åŸåˆ™ï¼Œå¹¶ç®€è¦è§£é‡ŠåŸå› ã€‚

å¯è€ƒè™‘çš„åŸåˆ™åŒ…æ‹¬ä½†ä¸é™äºï¼š
- æŒ‰éœ€åˆ†é…ï¼ˆä¼˜å…ˆæ»¡è¶³åŸºæœ¬ç”Ÿå­˜éœ€æ±‚ï¼‰
- æŒ‰åŠ³åˆ†é…ï¼ˆæ ¹æ®åŠ³åŠ¨åŠ›è´¡çŒ®åˆ†é…ï¼‰
- å¹³ç­‰åˆ†é…ï¼ˆæ¯äººæˆ–æ¯å®¶è·å¾—ç›¸åŒä»½é¢ï¼‰
- ç…§é¡¾å¼±åŠ¿ï¼ˆå¯¹å›°éš¾å®¶åº­ç»™äºˆæ›´å¤šæ”¯æŒï¼‰
- æ•ˆç‡ä¼˜å…ˆï¼ˆç¡®ä¿èµ„æºå¾—åˆ°æœ€æœ‰æ•ˆåˆ©ç”¨ï¼‰
- å¯æŒç»­å‘å±•ï¼ˆä¸ºé•¿æœŸå‘å±•ä¿ç•™èµ„æºï¼‰

è¯·ç”¨ä»¥ä¸‹æ ¼å¼å›ç­”ï¼š
åŸåˆ™1ï¼š[åŸåˆ™åç§°] - [ç®€è¦ç†ç”±]
åŸåˆ™2ï¼š[åŸåˆ™åç§°] - [ç®€è¦ç†ç”±] 
åŸåˆ™3ï¼š[åŸåˆ™åç§°] - [ç®€è¦ç†ç”±]
"""
        
        model_name = "deepseek-v3"
        temperature = 0.7
        
        try:
            start_time = time.time()
            response = client.chat.completions.create(
                model=model_name,
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªå‚ä¸ç¤¾åŒºåå•†çš„å®¶åº­ä»£è¡¨ï¼Œè¯·æ ¹æ®ä½ çš„ä»·å€¼è§‚å’Œå®¶åº­æƒ…å†µï¼ŒçœŸè¯šåœ°è¡¨è¾¾ä½ çš„åˆ†é…åŸåˆ™åå¥½ã€‚"},
                    {"role": "user", "content": prompt}
                ],
                temperature=temperature,
                max_tokens=400
            )
            duration = time.time() - start_time
            
            content = response.choices[0].message.content
            principles = self._parse_principles(content)
            
            # è®°å½•LLMäº¤äº’
            llm_logger = get_logger()
            if llm_logger:
                llm_logger.log_negotiation_call(
                    round_number=self.round_number,
                    stage="principles",
                    agent=agent,
                    input_prompt=prompt,
                    raw_output=content,
                    model=model_name,
                    temperature=temperature,
                    duration=duration,
                    success=True,
                    processed_data={
                        "principles": principles,
                        "summary": f"å¼ºè°ƒ{principles[0] if principles else 'å¹³è¡¡å‘å±•'}"
                    }
                )
            
            return {
                "raw_response": content,
                "principles": principles,
                "summary": f"å¼ºè°ƒ{principles[0] if principles else 'å¹³è¡¡å‘å±•'}"
            }
            
        except Exception as e:
            print(f"è·å–{agent['family_name']}å®¶åŸåˆ™åå¥½å¤±è´¥: {str(e)}")
            
            # è®°å½•å¤±è´¥çš„LLMè°ƒç”¨
            llm_logger = get_logger()
            if llm_logger:
                llm_logger.log_negotiation_call(
                    round_number=self.round_number,
                    stage="principles",
                    agent=agent,
                    input_prompt=prompt,
                    raw_output=f"è·å–å¤±è´¥: {str(e)}",
                    model=model_name,
                    temperature=temperature,
                    duration=0.0,
                    success=False
                )
            
            return {
                "raw_response": "è·å–å¤±è´¥",
                "principles": ["æŒ‰éœ€åˆ†é…", "å…¬å¹³åˆç†", "å¯æŒç»­å‘å±•"],
                "summary": "å¹³è¡¡å‘å±•"
            }
    
    def _parse_principles(self, content: str) -> List[str]:
        """è§£æåŸåˆ™å›å¤"""
        principles = []
        lines = content.split('\n')
        
        for line in lines:
            line = line.strip()
            if re.match(r'åŸåˆ™[123][:ï¼š]', line):
                # æå–åŸåˆ™åç§°ï¼ˆå†’å·å‰åˆ°ç¬¬ä¸€ä¸ª"-"æˆ–"â€”"ä¹‹é—´çš„éƒ¨åˆ†ï¼‰
                match = re.search(r'åŸåˆ™[123][:ï¼š]\s*([^-â€”]+)', line)
                if match:
                    principle = match.group(1).strip()
                    principles.append(principle)
        
        # å¦‚æœè§£æå¤±è´¥ï¼Œè¿”å›é»˜è®¤åŸåˆ™
        if not principles:
            principles = ["å…¬å¹³åˆ†é…", "æ»¡è¶³åŸºæœ¬éœ€æ±‚", "è€ƒè™‘è´¡çŒ®"]
        
        return principles[:3]  # æœ€å¤š3ä¸ªåŸåˆ™
    
    def _find_common_principles(self, principle_preferences: Dict[int, Dict[str, Any]]) -> Dict[str, str]:
        """å¯»æ‰¾å…±åŒåŸåˆ™"""
        # ç»Ÿè®¡æ‰€æœ‰æåˆ°çš„åŸåˆ™
        principle_counts = {}
        
        for agent_id, pref in principle_preferences.items():
            for principle in pref["principles"]:
                # å½’ä¸€åŒ–åŸåˆ™åç§°
                normalized = self._normalize_principle_name(principle)
                principle_counts[normalized] = principle_counts.get(normalized, 0) + 1
        
        # æ‰¾å‡ºå¤§å¤šæ•°äººæ”¯æŒçš„åŸåˆ™ï¼ˆè¶…è¿‡ä¸€åŠï¼‰
        threshold = len(self.agents) // 2 + 1
        common_principles = {}
        
        for principle, count in principle_counts.items():
            if count >= threshold:
                common_principles[principle] = f"è·å¾—{count}/{len(self.agents)}å®¶åº­æ”¯æŒ"
        
        return common_principles
    
    def _normalize_principle_name(self, principle: str) -> str:
        """å½’ä¸€åŒ–åŸåˆ™åç§°"""
        # ç®€å•çš„å…³é”®è¯åŒ¹é…å½’ä¸€åŒ–
        principle_lower = principle.lower()
        
        if any(word in principle_lower for word in ["æŒ‰éœ€", "éœ€æ±‚", "åŸºæœ¬éœ€è¦"]):
            return "æŒ‰éœ€åˆ†é…"
        elif any(word in principle_lower for word in ["æŒ‰åŠ³", "è´¡çŒ®", "åŠ³åŠ¨"]):
            return "æŒ‰åŠ³åˆ†é…"
        elif any(word in principle_lower for word in ["å¹³ç­‰", "å‡ç­‰", "ç›¸åŒ"]):
            return "å¹³ç­‰åˆ†é…"
        elif any(word in principle_lower for word in ["å¼±åŠ¿", "å›°éš¾", "ç…§é¡¾"]):
            return "ç…§é¡¾å¼±åŠ¿"
        elif any(word in principle_lower for word in ["æ•ˆç‡", "æœ‰æ•ˆ"]):
            return "æ•ˆç‡ä¼˜å…ˆ"
        elif any(word in principle_lower for word in ["å¯æŒç»­", "é•¿æœŸ", "å‘å±•"]):
            return "å¯æŒç»­å‘å±•"
        else:
            return principle  # ä¿æŒåŸå
    
    def _discuss_disputed_principles(self, principle_preferences: Dict[int, Dict[str, Any]], 
                                   common_principles: Dict[str, str]) -> Dict[str, str]:
        """è®¨è®ºæœ‰äº‰è®®çš„åŸåˆ™"""
        
        # æ‰¾å‡ºæœªè¾¾æˆå…±è¯†ä½†æœ‰æ”¯æŒçš„åŸåˆ™
        all_mentioned = {}
        for pref in principle_preferences.values():
            for principle in pref["principles"]:
                normalized = self._normalize_principle_name(principle)
                if normalized not in common_principles:
                    all_mentioned[normalized] = all_mentioned.get(normalized, 0) + 1
        
        # é€‰æ‹©æœ€æœ‰äº‰è®®çš„2ä¸ªåŸåˆ™è¿›è¡Œè®¨è®º
        disputed = sorted(all_mentioned.items(), key=lambda x: x[1], reverse=True)[:2]
        
        discussed_results = {}
        
        for principle_name, support_count in disputed:
            print(f"\n     è®¨è®ºåŸåˆ™ï¼š{principle_name} (å½“å‰æ”¯æŒåº¦ï¼š{support_count}/{len(self.agents)})")
            
            # è®©æ”¯æŒè€…å’Œåå¯¹è€…å„è‡ªè¡¨è¾¾è§‚ç‚¹
            discussion_result = self._moderate_principle_discussion(principle_name, principle_preferences)
            discussed_results[principle_name] = discussion_result
        
        return discussed_results
    
    def _moderate_principle_discussion(self, principle_name: str, 
                                     principle_preferences: Dict[int, Dict[str, Any]]) -> str:
        """ä¸»æŒåŸåˆ™è®¨è®º"""
        
        # æ‰¾å‡ºæ”¯æŒè€…å’Œåå¯¹è€…
        supporters = []
        others = []
        
        for agent in self.agents:
            agent_principles = [self._normalize_principle_name(p) for p in 
                             principle_preferences[agent["id"]]["principles"]]
            if principle_name in agent_principles:
                supporters.append(agent)
            else:
                others.append(agent)
        
        # è®°å½•äº‰è®®
        if self.logger and len(supporters) > 1 and len(others) > 0:
            self.logger.log_conflict(
                conflict_topic=f"åŸåˆ™ï¼š{principle_name}",
                conflicting_parties=[agent["id"] for agent in others],
                conflict_description=f"{len(supporters)}å®¶æ”¯æŒï¼Œ{len(others)}å®¶åå¯¹æˆ–ä¸­ç«‹"
            )
        
        # å¦‚æœæ”¯æŒè€…è¿‡å°‘ï¼Œç›´æ¥æ”¾å¼ƒ
        if len(supporters) <= 1:
            return f"æ”¯æŒåº¦ä¸è¶³ï¼Œä¸é‡‡çº³"
        
        # è®©ä¸€ä¸ªæ”¯æŒè€…è¿›è¡Œè¯´æœ
        if supporters:
            advocate = supporters[0]  # é€‰æ‹©ç¬¬ä¸€ä¸ªæ”¯æŒè€…ä½œä¸ºå€¡å¯¼è€…
            persuasion = self._generate_principle_persuasion(advocate, principle_name)
            
            # è®°å½•è¯´æœå‘è¨€
            if self.logger:
                self.logger.log_discussion_turn(
                    speaker_id=advocate["id"],
                    speaker_name=advocate["family_name"],
                    speaker_value_type=advocate["value_type"],
                    content=persuasion,
                    speech_type="persuasion",
                    target_topic=f"ä¸ºåŸåˆ™'{principle_name}'è¯´æœ"
                )
            
            # è¯„ä¼°è¯´æœæ•ˆæœ
            convinced_count = self._evaluate_persuasion_effect(persuasion, others, principle_name)
            
            total_support = len(supporters) + convinced_count
            result_msg = ""
            if total_support >= len(self.agents) // 2 + 1:
                result_msg = f"ç»è®¨è®ºåè·å¾—{total_support}/{len(self.agents)}å®¶åº­æ”¯æŒï¼Œé‡‡çº³"
                # è®°å½•å†³ç­–
                if self.logger:
                    self.logger.log_decision(
                        decision_type="principle_adopted",
                        decision_content={principle_name: "é‡‡çº³"},
                        supporters=[agent["id"] for agent in supporters] + [others[i]["id"] for i in range(convinced_count)],
                        opponents=[agent["id"] for agent in others[convinced_count:]]
                    )
            else:
                result_msg = f"è®¨è®ºåä»åªæœ‰{total_support}/{len(self.agents)}å®¶åº­æ”¯æŒï¼Œä¸é‡‡çº³"
                
            return result_msg
        
        return "è®¨è®ºæ— ç»“æœ"
    
    def _generate_principle_persuasion(self, advocate: Dict[str, Any], principle_name: str) -> str:
        """ç”ŸæˆåŸåˆ™è¯´æœè®ºè¿°"""
        prompt = f"""ä½ æ˜¯{advocate['family_name']}å®¶åº­çš„ä»£è¡¨ï¼Œä½ æ”¯æŒ"{principle_name}"è¿™ä¸ªåˆ†é…åŸåˆ™ã€‚

ç°åœ¨éœ€è¦ä½ å‘å…¶ä»–å®¶åº­è§£é‡Šä¸ºä»€ä¹ˆè¿™ä¸ªåŸåˆ™å¯¹æ•´ä¸ªç¤¾åŒºæœ‰ç›Šï¼Œå°è¯•è¯´æœä»–ä»¬æ”¯æŒè¿™ä¸ªåŸåˆ™ã€‚

ä½ çš„å®¶åº­èƒŒæ™¯ï¼š{advocate['background']}
ä½ çš„æ ¸å¿ƒä¿¡å¿µï¼š{advocate['core_beliefs'][0]}

ç¤¾åŒºæƒ…å†µï¼š
- æ€»èµ„æºï¼š{self.total_grain:.1f}å•ä½å†œä½œç‰©
- æ€»äººå£ï¼š{self.total_members}äºº
- æ€»åŠ³åŠ¨åŠ›ï¼š{self.total_labor}äºº

è¯·ç”¨ç®€æ´æœ‰åŠ›çš„è¯­è¨€ï¼ˆä¸è¶…è¿‡100å­—ï¼‰è§£é‡Šï¼š
1. ä¸ºä»€ä¹ˆè¿™ä¸ªåŸåˆ™ç¬¦åˆç¤¾åŒºæ•´ä½“åˆ©ç›Š
2. è¿™ä¸ªåŸåˆ™å¦‚ä½•å¸®åŠ©ç¤¾åŒºé•¿æœŸå‘å±•
3. å‘¼åå…¶ä»–å®¶åº­æ”¯æŒ

è¦æ±‚ï¼šè¯­è¨€çœŸè¯šã€è®ºæ®åˆç†ã€è€ƒè™‘å…¶ä»–å®¶åº­çš„åˆ©ç›Šã€‚
"""
        
        model_name = "deepseek-v3"
        temperature = 0.6
        
        try:
            start_time = time.time()
            response = client.chat.completions.create(
                model=model_name,
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªå–„äºæ²Ÿé€šå’Œè¯´æœçš„ç¤¾åŒºä»£è¡¨ï¼Œè¯·ç”¨çœŸè¯šå’Œç†æ€§çš„æ–¹å¼è¿›è¡Œè®ºè¿°ã€‚"},
                    {"role": "user", "content": prompt}
                ],
                temperature=temperature,
                max_tokens=200
            )
            duration = time.time() - start_time
            
            content = response.choices[0].message.content
            
            # è®°å½•LLMäº¤äº’
            llm_logger = get_logger()
            if llm_logger:
                llm_logger.log_negotiation_call(
                    round_number=self.round_number,
                    stage="principles-persuasion",
                    agent=advocate,
                    input_prompt=prompt,
                    raw_output=content,
                    model=model_name,
                    temperature=temperature,
                    duration=duration,
                    success=True,
                    processed_data={
                        "principle_name": principle_name,
                        "persuasion_type": "è¯´æœå…¶ä»–å®¶åº­æ”¯æŒåŸåˆ™"
                    }
                )
            
            return content
            
        except Exception as e:
            fallback = f"æˆ‘è®¤ä¸º{principle_name}å¯¹æˆ‘ä»¬ç¤¾åŒºçš„é•¿æœŸå‘å±•å¾ˆé‡è¦ï¼Œå¸Œæœ›å¤§å®¶èƒ½å¤Ÿæ”¯æŒã€‚"
            
            # è®°å½•å¤±è´¥çš„LLMè°ƒç”¨
            llm_logger = get_logger()
            if llm_logger:
                llm_logger.log_negotiation_call(
                    round_number=self.round_number,
                    stage="principles-persuasion",
                    agent=advocate,
                    input_prompt=prompt,
                    raw_output=f"è·å–å¤±è´¥: {str(e)}",
                    model=model_name,
                    temperature=temperature,
                    duration=0.0,
                    success=False
                )
            
            return fallback
    
    def _evaluate_persuasion_effect(self, persuasion: str, others: List[Dict[str, Any]], 
                                   principle_name: str) -> int:
        """è¯„ä¼°è¯´æœæ•ˆæœ"""
        convinced_count = 0
        
        for agent in others:
            # ç®€åŒ–çš„è¯´æœæ•ˆæœè¯„ä¼°
            agent_value = agent["value_type"]
            
            # æ ¹æ®ä»·å€¼è§‚åŒ¹é…åº¦åˆ¤æ–­æ˜¯å¦è¢«è¯´æœ
            if principle_name == "æŒ‰éœ€åˆ†é…" and agent_value in ["needs_based", "altruistic"]:
                convinced_count += 1
            elif principle_name == "æŒ‰åŠ³åˆ†é…" and agent_value in ["merit_based", "pragmatic"]:
                convinced_count += 1
            elif principle_name == "å¹³ç­‰åˆ†é…" and agent_value in ["egalitarian", "altruistic"]:
                convinced_count += 1
            elif principle_name == "ç…§é¡¾å¼±åŠ¿" and agent_value in ["altruistic", "needs_based"]:
                convinced_count += 1
            elif principle_name == "æ•ˆç‡ä¼˜å…ˆ" and agent_value in ["merit_based", "pragmatic"]:
                convinced_count += 1
            elif principle_name == "å¯æŒç»­å‘å±•" and agent_value == "pragmatic":
                convinced_count += 1
        
        return convinced_count
    
    def _negotiate_framework(self, principles: Dict[str, str]) -> Dict[str, Any]:
        """é˜¶æ®µ2ï¼šåå•†åˆ†é…æ¡†æ¶"""
        self.current_stage = "framework"
        
        # å¼€å§‹æ¡†æ¶åå•†é˜¶æ®µ
        if self.logger:
            self.logger.start_stage("negotiate_framework", [agent["id"] for agent in self.agents])
        
        print("\n   åŸºäºç¡®å®šçš„åŸåˆ™ï¼Œæ„å»ºåˆ†é…æ¡†æ¶...")
        
        # 2.1 æ ¹æ®åŸåˆ™ç¡®å®šåˆ†é…ç­–ç•¥
        allocation_strategy = self._determine_allocation_strategy(principles)
        
        # è®°å½•ç­–ç•¥å†³å®š
        if self.logger:
            self.logger.log_decision(
                decision_type="allocation_strategy_determined",
                decision_content=allocation_strategy,
                supporters=[agent["id"] for agent in self.agents],
                opponents=[]
            )
        
        # 2.2 åå•†å…·ä½“çš„åˆ†é…æ¯”ä¾‹
        print("\n   åå•†å…·ä½“åˆ†é…æ¯”ä¾‹...")
        allocation_ratios = self._negotiate_allocation_ratios(principles, allocation_strategy)
        
        # 2.3 ç¡®å®šä¼˜å…ˆçº§é¡ºåº
        print("\n   ç¡®å®šåˆ†é…ä¼˜å…ˆçº§...")
        priority_order = self._establish_priority_order(principles)
        
        framework = {
            "strategy": allocation_strategy,
            "ratios": allocation_ratios,
            "priority_order": priority_order,
            "based_on_principles": list(principles.keys())
        }
        
        print(f"\n   æ¡†æ¶ç¡®å®šï¼š{allocation_strategy['name']}")
        
        # ç»“æŸæ¡†æ¶é˜¶æ®µ
        if self.logger:
            self.logger.end_stage(
                stage_outcome=f"ç¡®å®šäº†{allocation_strategy['name']}åˆ†é…æ¡†æ¶",
                consensus_level=0.9  # å‡è®¾æ¡†æ¶é˜¶æ®µé€šå¸¸èƒ½è¾¾æˆè¾ƒé«˜å…±è¯†
            )
        
        return framework
    
    def _determine_allocation_strategy(self, principles: Dict[str, str]) -> Dict[str, Any]:
        """æ ¹æ®åŸåˆ™ç¡®å®šåˆ†é…ç­–ç•¥"""
        
        principle_names = list(principles.keys())
        
        # æ ¹æ®ä¸»å¯¼åŸåˆ™ç¡®å®šç­–ç•¥
        if "æŒ‰éœ€åˆ†é…" in principle_names and "ç…§é¡¾å¼±åŠ¿" in principle_names:
            return {
                "name": "éœ€æ±‚ä¼˜å…ˆç­–ç•¥",
                "description": "ä¼˜å…ˆæ»¡è¶³åŸºæœ¬éœ€æ±‚ï¼Œç‰¹åˆ«ç…§é¡¾å›°éš¾å®¶åº­",
                "base_method": "needs_first"
            }
        elif "æŒ‰åŠ³åˆ†é…" in principle_names and "æ•ˆç‡ä¼˜å…ˆ" in principle_names:
            return {
                "name": "è´¡çŒ®å¯¼å‘ç­–ç•¥", 
                "description": "æ ¹æ®åŠ³åŠ¨è´¡çŒ®åˆ†é…ï¼Œæ¿€åŠ±é«˜æ•ˆç”Ÿäº§",
                "base_method": "contribution_based"
            }
        elif "å¹³ç­‰åˆ†é…" in principle_names:
            return {
                "name": "å¹³ç­‰åŸºç¡€ç­–ç•¥",
                "description": "åœ¨ä¿è¯åŸºæœ¬éœ€æ±‚å‰æä¸‹å°½é‡å¹³ç­‰åˆ†é…",
                "base_method": "equality_based"
            }
        else:
            return {
                "name": "æ··åˆå¹³è¡¡ç­–ç•¥",
                "description": "ç»¼åˆè€ƒè™‘å¤šç§å› ç´ çš„å¹³è¡¡åˆ†é…",
                "base_method": "balanced_hybrid"
            }
    
    def _negotiate_allocation_ratios(self, principles: Dict[str, str], 
                                   strategy: Dict[str, Any]) -> Dict[str, float]:
        """åå•†åˆ†é…æ¯”ä¾‹"""
        
        # åŸºäºç­–ç•¥å’ŒåŸåˆ™ç¡®å®šåˆå§‹æ¯”ä¾‹
        base_ratios = self._get_base_ratios(strategy)
        
        # è®©ä»£ç†è®¨è®ºå’Œè°ƒæ•´æ¯”ä¾‹
        adjusted_ratios = self._discuss_ratio_adjustments(base_ratios, principles)
        
        return adjusted_ratios
    
    def _get_base_ratios(self, strategy: Dict[str, Any]) -> Dict[str, float]:
        """è·å–åŸºç¡€åˆ†é…æ¯”ä¾‹"""
        
        if strategy["base_method"] == "needs_first":
            return {
                "survival_guarantee": 0.6,  # 60%ç”¨äºä¿è¯ç”Ÿå­˜éœ€æ±‚
                "additional_support": 0.25,  # 25%ç”¨äºé¢å¤–æ”¯æŒ
                "community_reserve": 0.15   # 15%ä½œä¸ºç¤¾åŒºå‚¨å¤‡
            }
        elif strategy["base_method"] == "contribution_based":
            return {
                "survival_guarantee": 0.4,  # 40%ä¿è¯åŸºæœ¬ç”Ÿå­˜
                "contribution_reward": 0.5,  # 50%æŒ‰è´¡çŒ®åˆ†é…
                "community_reserve": 0.1    # 10%ç¤¾åŒºå‚¨å¤‡
            }
        elif strategy["base_method"] == "equality_based":
            return {
                "survival_guarantee": 0.5,  # 50%ä¿è¯ç”Ÿå­˜
                "equal_distribution": 0.4,  # 40%å¹³ç­‰åˆ†é…
                "community_reserve": 0.1    # 10%å‚¨å¤‡
            }
        else:  # balanced_hybrid
            return {
                "survival_guarantee": 0.45,  # 45%ä¿è¯ç”Ÿå­˜
                "merit_portion": 0.25,      # 25%æŒ‰è´¡çŒ®
                "equal_portion": 0.2,       # 20%å¹³ç­‰åˆ†é…
                "community_reserve": 0.1    # 10%å‚¨å¤‡
            }
    
    def _discuss_ratio_adjustments(self, base_ratios: Dict[str, float], 
                                 principles: Dict[str, str]) -> Dict[str, float]:
        """è®¨è®ºæ¯”ä¾‹è°ƒæ•´"""
        
        print(f"    åˆå§‹æ¯”ä¾‹æ–¹æ¡ˆï¼š{base_ratios}")
        
        # å¾æ±‚å„å®¶åº­å¯¹æ¯”ä¾‹çš„æ„è§
        adjustment_suggestions = {}
        
        for agent in self.agents:
            suggestion = self._get_ratio_adjustment_suggestion(agent, base_ratios, principles)
            adjustment_suggestions[agent["id"]] = suggestion
            
            if suggestion["has_adjustment"]:
                print(f"    {agent['family_name']}å®¶å»ºè®®ï¼š{suggestion['suggestion']}")
                
                # è®°å½•æ¯”ä¾‹è°ƒæ•´å»ºè®®
                if self.logger:
                    self.logger.log_discussion_turn(
                        speaker_id=agent["id"],
                        speaker_name=agent["family_name"],
                        speaker_value_type=agent["value_type"],
                        content=suggestion["suggestion"],
                        speech_type="ratio_adjustment_suggestion",
                        target_topic="åˆ†é…æ¯”ä¾‹è°ƒæ•´"
                    )
        
        # æ‰¾å‡ºæœ‰å…±è¯†çš„è°ƒæ•´
        final_ratios = self._apply_consensus_adjustments(base_ratios, adjustment_suggestions)
        
        print(f"    æœ€ç»ˆæ¯”ä¾‹æ–¹æ¡ˆï¼š{final_ratios}")
        return final_ratios
    
    def _get_ratio_adjustment_suggestion(self, agent: Dict[str, Any], base_ratios: Dict[str, float],
                                       principles: Dict[str, str]) -> Dict[str, Any]:
        """è·å–æ¯”ä¾‹è°ƒæ•´å»ºè®®"""
        
        # æ ¹æ®ä»£ç†ä»·å€¼è§‚åˆ¤æ–­æ˜¯å¦éœ€è¦è°ƒæ•´
        value_type = agent["value_type"]
        has_adjustment = False
        suggestion = ""
        
        if value_type == "altruistic" and base_ratios.get("survival_guarantee", 0) < 0.5:
            has_adjustment = True
            suggestion = "å»ºè®®æé«˜ç”Ÿå­˜ä¿éšœæ¯”ä¾‹åˆ°50%ä»¥ä¸Š"
        elif value_type == "merit_based" and base_ratios.get("contribution_reward", 0) < 0.4:
            has_adjustment = True
            suggestion = "å»ºè®®æé«˜æŒ‰è´¡çŒ®åˆ†é…çš„æ¯”ä¾‹"
        elif value_type == "egalitarian" and base_ratios.get("equal_distribution", 0) < 0.3:
            has_adjustment = True
            suggestion = "å»ºè®®å¢åŠ å¹³ç­‰åˆ†é…çš„æ¯”ä¾‹"
        
        return {
            "has_adjustment": has_adjustment,
            "suggestion": suggestion,
            "agent_id": agent["id"]
        }
    
    def _apply_consensus_adjustments(self, base_ratios: Dict[str, float], 
                                   suggestions: Dict[int, Dict[str, Any]]) -> Dict[str, float]:
        """åº”ç”¨æœ‰å…±è¯†çš„è°ƒæ•´"""
        
        # ç®€åŒ–å¤„ç†ï¼šå¦‚æœè¶…è¿‡ä¸€åŠä»£ç†å»ºè®®åŒæ ·çš„è°ƒæ•´ï¼Œåˆ™åº”ç”¨
        adjusted_ratios = base_ratios.copy()
        
        # ç»Ÿè®¡è°ƒæ•´å»ºè®®
        adjustment_counts = {}
        for suggestion in suggestions.values():
            if suggestion["has_adjustment"]:
                key = suggestion["suggestion"]
                adjustment_counts[key] = adjustment_counts.get(key, 0) + 1
        
        # åº”ç”¨æœ‰å…±è¯†çš„è°ƒæ•´ï¼ˆè¶…è¿‡ä¸€åŠæ”¯æŒï¼‰
        threshold = len(self.agents) // 2 + 1
        
        for adjustment, count in adjustment_counts.items():
            if count >= threshold:
                # ç®€åŒ–çš„è°ƒæ•´é€»è¾‘
                if "ç”Ÿå­˜ä¿éšœ" in adjustment and "50%" in adjustment:
                    if "survival_guarantee" in adjusted_ratios:
                        old_value = adjusted_ratios["survival_guarantee"]
                        adjusted_ratios["survival_guarantee"] = max(0.5, old_value)
                        # ç›¸åº”è°ƒæ•´å…¶ä»–æ¯”ä¾‹
                        self._rebalance_ratios(adjusted_ratios)
        
        return adjusted_ratios
    
    def _rebalance_ratios(self, ratios: Dict[str, float]) -> None:
        """é‡æ–°å¹³è¡¡æ¯”ä¾‹ï¼Œç¡®ä¿æ€»å’Œä¸º1"""
        total = sum(ratios.values())
        if total != 1.0:
            # æŒ‰æ¯”ä¾‹è°ƒæ•´æ‰€æœ‰é¡¹ç›®
            for key in ratios:
                ratios[key] = ratios[key] / total
    
    def _establish_priority_order(self, principles: Dict[str, str]) -> List[str]:
        """ç¡®å®šåˆ†é…ä¼˜å…ˆçº§é¡ºåº"""
        
        priority_order = []
        
        # åŸºäºåŸåˆ™ç¡®å®šä¼˜å…ˆçº§
        if "æŒ‰éœ€åˆ†é…" in principles or "ç…§é¡¾å¼±åŠ¿" in principles:
            priority_order.append("æ»¡è¶³åŸºæœ¬ç”Ÿå­˜éœ€æ±‚")
        
        if "æŒ‰åŠ³åˆ†é…" in principles:
            priority_order.append("æŒ‰åŠ³åŠ¨è´¡çŒ®åˆ†é…")
        
        if "å¹³ç­‰åˆ†é…" in principles:
            priority_order.append("ä¿è¯åˆ†é…å…¬å¹³æ€§")
        
        if "å¯æŒç»­å‘å±•" in principles:
            priority_order.append("é¢„ç•™å‘å±•èµ„æº")
        
        # ç¡®ä¿è‡³å°‘æœ‰åŸºæœ¬ä¼˜å…ˆçº§
        if not priority_order:
            priority_order = ["æ»¡è¶³åŸºæœ¬ç”Ÿå­˜éœ€æ±‚", "å…¬å¹³åˆç†åˆ†é…"]
        
        return priority_order
    
    def _build_detailed_proposal(self, framework: Dict[str, Any]) -> Dict[int, Dict[str, float]]:
        """é˜¶æ®µ3ï¼šæ„å»ºè¯¦ç»†åˆ†é…æ–¹æ¡ˆï¼ˆåŒ…å«LLMé©±åŠ¨çš„åå•†ï¼‰"""
        self.current_stage = "details"
        
        # å¼€å§‹é˜¶æ®µæ—¥å¿—
        if self.logger:
            try:
                self.logger.start_stage("details", [agent["id"] for agent in self.agents])
            except Exception:
                pass
        
        print("\n   æ ¹æ®æ¡†æ¶è®¡ç®—åˆæ­¥åˆ†é…æ–¹æ¡ˆ...")
        
        # 3.1 è®¡ç®—åˆæ­¥åŸºç¡€åˆ†é…
        initial_allocation = self._calculate_base_allocation(framework)
        initial_allocation = self._handle_special_cases(initial_allocation, framework)
        initial_allocation = self._validate_and_optimize(initial_allocation)
        
        print("\n   åˆæ­¥åˆ†é…æ–¹æ¡ˆï¼š")
        for agent in self.agents:
            agent_id = agent["id"]
            allocation = initial_allocation.get(agent_id, {})
            total = sum(allocation.values())
            print(f"    {agent['family_name']}å®¶ï¼š{total:.2f}å•ä½")
        
        # è®°å½•åˆæ­¥åˆ†é…
        if self.logger:
            try:
                per_agent_totals = {aid: sum(res.values()) for aid, res in initial_allocation.items()}
                self.logger.log_decision(
                    decision_type="initial_allocation_proposed",
                    decision_content={
                        "strategy": framework.get("strategy", {}),
                        "ratios": framework.get("ratios", {}),
                        "per_agent_total": per_agent_totals
                    },
                    supporters=[agent["id"] for agent in self.agents],
                    opponents=[]
                )
            except Exception:
                pass
        
        # ğŸ¯ 3.2 è®©å„å®¶åº­å¯¹åˆæ­¥æ–¹æ¡ˆå‘è¡¨æ„è§å’Œæå‡ºè°ƒæ•´è¯·æ±‚
        print("\n   å¾æ±‚å„å®¶åº­å¯¹åˆæ­¥æ–¹æ¡ˆçš„æ„è§...")
        allocation_opinions = self._collect_allocation_opinions(initial_allocation, framework)
        
        # ğŸ¯ 3.3 è¯†åˆ«æœ‰äº‰è®®çš„åˆ†é…å¹¶è¿›è¡Œè®¨è®º
        print("\n   å¤„ç†åˆ†é…å¼‚è®®...")
        disputed_agents = [aid for aid, op in allocation_opinions.items() 
                          if op.get("has_objection", False)]
        
        if disputed_agents:
            print(f"    å‘ç° {len(disputed_agents)} å®¶æå‡ºå¼‚è®®ï¼Œå¼€å§‹åå•†...")
            negotiated_allocation = self._negotiate_disputed_allocations(
                initial_allocation, allocation_opinions, framework
            )
        else:
            print("    å„å®¶åº­æ— é‡å¤§å¼‚è®®")
            negotiated_allocation = initial_allocation
        
        # 3.4 æœ€ç»ˆéªŒè¯
        print("\n   æœ€ç»ˆåˆ†é…æ–¹æ¡ˆï¼š")
        final_allocation = self._validate_and_optimize(negotiated_allocation)
        for agent in self.agents:
            agent_id = agent["id"]
            allocation = final_allocation.get(agent_id, {})
            total = sum(allocation.values())
            print(f"    {agent['family_name']}å®¶ï¼š{total:.2f}å•ä½")
        
        # ç»“æŸé˜¶æ®µæ—¥å¿—
        if self.logger:
            try:
                satisfied = 0
                for agent in self.agents:
                    aid = agent["id"]
                    got = sum(final_allocation.get(aid, {}).values())
                    need = sum(self.survival_needs.get(aid, {}).values())
                    if need <= 0 or got >= need:
                        satisfied += 1
                consensus_level = satisfied / len(self.agents) if self.agents else 0.0
                self.logger.end_stage(
                    stage_outcome="è¯¦ç»†æ–¹æ¡ˆåå•†å®Œæˆ",
                    consensus_level=consensus_level
                )
            except Exception:
                pass
        
        return final_allocation
    
    def _calculate_base_allocation(self, framework: Dict[str, Any]) -> Dict[int, Dict[str, float]]:
        """è®¡ç®—åŸºç¡€åˆ†é…"""
        
        strategy = framework["strategy"]["base_method"]
        ratios = framework["ratios"]
        
        if strategy == "needs_first":
            return self._calculate_needs_first_allocation(ratios)
        elif strategy == "contribution_based":
            return self._calculate_contribution_allocation(ratios)
        elif strategy == "equality_based":
            return self._calculate_equality_allocation(ratios)
        else:  # balanced_hybrid
            return self._calculate_hybrid_allocation(ratios)
    
    def _calculate_needs_first_allocation(self, ratios: Dict[str, float]) -> Dict[int, Dict[str, float]]:
        """éœ€æ±‚ä¼˜å…ˆåˆ†é…è®¡ç®—"""
        allocation = self._initialize_empty_proposal()
        
        # ç¬¬ä¸€æ­¥ï¼šä¿è¯ç”Ÿå­˜éœ€æ±‚
        survival_budget = self.total_grain * ratios["survival_guarantee"]
        remaining_budget = self.total_grain - survival_budget
        
        # æ»¡è¶³æ‰€æœ‰å®¶åº­çš„åŸºæœ¬ç”Ÿå­˜éœ€æ±‚
        total_survival_needs = sum(
            sum(needs.values()) for needs in self.survival_needs.values()
        )
        
        for agent in self.agents:
            agent_id = agent["id"]
            agent_needs = sum(self.survival_needs.get(agent_id, {}).values())
            
            if total_survival_needs > 0:
                survival_share = (agent_needs / total_survival_needs) * survival_budget
                allocation[agent_id]["grain"] = survival_share
        
        # ç¬¬äºŒæ­¥ï¼šå‰©ä½™èµ„æºæŒ‰éœ€æ±‚ç¨‹åº¦åˆ†é…
        if remaining_budget > 0:
            # è®¡ç®—å„å®¶åº­çš„éœ€æ±‚å¼ºåº¦ï¼ˆè€ƒè™‘å®¶åº­è§„æ¨¡å’Œä¾èµ–æ¯”ï¼‰
            need_weights = {}
            total_weight = 0
            
            for agent in self.agents:
                agent_id = agent["id"]
                members = agent["members"]
                labor_force = agent["labor_force"]
                dependency_ratio = members / labor_force if labor_force > 0 else 2.0
                
                # éœ€æ±‚æƒé‡ = æˆå‘˜æ•° * ä¾èµ–æ¯”
                weight = members * dependency_ratio
                need_weights[agent_id] = weight
                total_weight += weight
            
            # æŒ‰æƒé‡åˆ†é…å‰©ä½™èµ„æº
            for agent in self.agents:
                agent_id = agent["id"]
                if total_weight > 0:
                    additional_share = (need_weights[agent_id] / total_weight) * remaining_budget
                    allocation[agent_id]["grain"] += additional_share
        
        return allocation
    
    def _calculate_contribution_allocation(self, ratios: Dict[str, float]) -> Dict[int, Dict[str, float]]:
        """è´¡çŒ®å¯¼å‘åˆ†é…è®¡ç®—"""
        allocation = self._initialize_empty_proposal()
        
        # ç¬¬ä¸€æ­¥ï¼šä¿è¯åŸºæœ¬ç”Ÿå­˜
        survival_budget = self.total_grain * ratios["survival_guarantee"]
        contribution_budget = self.total_grain * ratios["contribution_reward"]
        
        # æŒ‰æœ€ä½éœ€æ±‚åˆ†é…ç”Ÿå­˜èµ„æº
        for agent in self.agents:
            agent_id = agent["id"]
            min_survival = sum(self.survival_needs.get(agent_id, {}).values())
            allocation[agent_id]["grain"] = min_survival
        
        # ç¬¬äºŒæ­¥ï¼šæŒ‰åŠ³åŠ¨åŠ›è´¡çŒ®åˆ†é…å‰©ä½™èµ„æº
        if self.total_labor > 0:
            for agent in self.agents:
                agent_id = agent["id"]
                labor_force = agent["labor_force"]
                contribution_share = (labor_force / self.total_labor) * contribution_budget
                allocation[agent_id]["grain"] += contribution_share
        
        return allocation
    
    def _calculate_equality_allocation(self, ratios: Dict[str, float]) -> Dict[int, Dict[str, float]]:
        """å¹³ç­‰åˆ†é…è®¡ç®—"""
        allocation = self._initialize_empty_proposal()
        
        # ç®€å•çš„å¹³ç­‰åˆ†é…
        per_family_share = self.total_grain / len(self.agents)
        
        for agent in self.agents:
            agent_id = agent["id"]
            allocation[agent_id]["grain"] = per_family_share
        
        return allocation
    
    def _calculate_hybrid_allocation(self, ratios: Dict[str, float]) -> Dict[int, Dict[str, float]]:
        """æ··åˆåˆ†é…è®¡ç®—"""
        allocation = self._initialize_empty_proposal()
        
        # å¤šå±‚åˆ†é…
        survival_budget = self.total_grain * ratios["survival_guarantee"]
        merit_budget = self.total_grain * ratios["merit_portion"]
        equal_budget = self.total_grain * ratios["equal_portion"]
        
        # å±‚1ï¼šç”Ÿå­˜ä¿éšœ
        for agent in self.agents:
            agent_id = agent["id"]
            min_survival = sum(self.survival_needs.get(agent_id, {}).values())
            allocation[agent_id]["grain"] = min(min_survival, survival_budget / len(self.agents))
        
        # å±‚2ï¼šæŒ‰åŠ³åˆ†é…
        if self.total_labor > 0:
            for agent in self.agents:
                agent_id = agent["id"]
                labor_share = (agent["labor_force"] / self.total_labor) * merit_budget
                allocation[agent_id]["grain"] += labor_share
        
        # å±‚3ï¼šå¹³ç­‰åˆ†é…
        equal_share = equal_budget / len(self.agents)
        for agent in self.agents:
            agent_id = agent["id"]
            allocation[agent_id]["grain"] += equal_share
        
        return allocation
    
    def _handle_special_cases(self, base_allocation: Dict[int, Dict[str, float]], 
                            framework: Dict[str, Any]) -> Dict[int, Dict[str, float]]:
        """å¤„ç†ç‰¹æ®Šæƒ…å†µ"""
        adjusted_allocation = copy.deepcopy(base_allocation)
        
        # æ£€æŸ¥æ˜¯å¦æœ‰å®¶åº­åˆ†é…è¿‡å°‘
        for agent in self.agents:
            agent_id = agent["id"]
            min_survival = sum(self.survival_needs.get(agent_id, {}).values())
            current_allocation = adjusted_allocation[agent_id]["grain"]
            
            if current_allocation < min_survival:
                # éœ€è¦ä»å…¶ä»–å®¶åº­è°ƒé…èµ„æº
                deficit = min_survival - current_allocation
                # è®°å½•å†²çªï¼šç”Ÿå­˜æœªæ»¡è¶³
                if self.logger:
                    try:
                        self.logger.log_conflict(
                            conflict_topic="ç”Ÿå­˜æœªæ»¡è¶³",
                            conflicting_parties=[agent_id],
                            conflict_description=f"ç¼ºå£={deficit:.2f}"
                        )
                    except Exception:
                        pass
                self._redistribute_for_survival(adjusted_allocation, agent_id, deficit)
        
        return adjusted_allocation
    
    def _redistribute_for_survival(self, allocation: Dict[int, Dict[str, float]], 
                                 needy_agent_id: int, deficit: float) -> None:
        """ä¸ºä¿è¯ç”Ÿå­˜éœ€æ±‚é‡æ–°åˆ†é…èµ„æº"""
        
        # æ‰¾å‡ºæœ‰å‰©ä½™çš„å®¶åº­
        surplus_agents = []
        
        for agent in self.agents:
            agent_id = agent["id"]
            if agent_id == needy_agent_id:
                continue
                
            current = allocation[agent_id]["grain"]
            min_needed = sum(self.survival_needs.get(agent_id, {}).values())
            
            if current > min_needed:
                surplus = current - min_needed
                surplus_agents.append((agent_id, surplus))
        
        # æŒ‰å‰©ä½™é‡æ’åºï¼Œä»å‰©ä½™æœ€å¤šçš„å¼€å§‹è°ƒé…
        surplus_agents.sort(key=lambda x: x[1], reverse=True)
        
        remaining_deficit = deficit
        
        for agent_id, surplus in surplus_agents:
            if remaining_deficit <= 0:
                break
            
            transfer_amount = min(surplus * 0.5, remaining_deficit)  # æœ€å¤šè½¬ç§»ä¸€åŠå‰©ä½™
            
            allocation[agent_id]["grain"] -= transfer_amount
            allocation[needy_agent_id]["grain"] += transfer_amount
            remaining_deficit -= transfer_amount
            
            # è®°å½•æ¯ç¬”å†åˆ†é…
            if self.logger and transfer_amount > 0:
                try:
                    self.logger.log_decision(
                        decision_type="survival_redistribution",
                        decision_content={
                            "from": agent_id,
                            "to": needy_agent_id,
                            "amount": transfer_amount
                        },
                        supporters=[agent_id],
                        opponents=[]
                    )
                except Exception:
                    pass
    
    def _collect_allocation_opinions(self, allocation: Dict[int, Dict[str, float]], 
                                   framework: Dict[str, Any]) -> Dict[int, Dict[str, Any]]:
        """æ”¶é›†å„å®¶åº­å¯¹åˆæ­¥åˆ†é…æ–¹æ¡ˆçš„æ„è§"""
        opinions = {}
        
        for agent in self.agents:
            agent_id = agent["id"]
            allocated_amount = sum(allocation.get(agent_id, {}).values())
            survival_need = sum(self.survival_needs.get(agent_id, {}).values())
            
            opinion = self._get_allocation_opinion(
                agent, allocated_amount, survival_need, allocation, framework
            )
            opinions[agent_id] = opinion
            
            # è®°å½•æ„è§
            if self.logger and opinion.get("has_objection"):
                self.logger.log_discussion_turn(
                    speaker_id=agent_id,
                    speaker_name=agent["family_name"],
                    speaker_value_type=agent["value_type"],
                    content=opinion.get("objection_reason", ""),
                    speech_type="allocation_objection",
                    target_topic="åˆæ­¥åˆ†é…æ–¹æ¡ˆ"
                )
        
        return opinions
    
    def _get_allocation_opinion(self, agent: Dict[str, Any], allocated_amount: float,
                              survival_need: float, all_allocations: Dict[int, Dict[str, float]],
                              framework: Dict[str, Any]) -> Dict[str, Any]:
        """è·å–å•ä¸ªå®¶åº­å¯¹åˆ†é…æ–¹æ¡ˆçš„æ„è§ï¼ˆLLMé©±åŠ¨ï¼‰"""
        
        # æ„å»ºå…¶ä»–å®¶åº­åˆ†é…æƒ…å†µçš„æè¿°
        other_allocations_str = ""
        for other_agent in self.agents:
            if other_agent["id"] != agent["id"]:
                other_amount = sum(all_allocations.get(other_agent["id"], {}).values())
                other_need = sum(self.survival_needs.get(other_agent["id"], {}).values())
                other_allocations_str += f"- {other_agent['family_name']}å®¶ï¼ˆ{other_agent['members']}äººï¼Œ{other_agent['labor_force']}åŠ³åŠ›ï¼‰ï¼šåˆ†é…{other_amount:.1f}å•ä½ï¼Œç”Ÿå­˜éœ€æ±‚{other_need:.1f}\n"
        
        prompt = f"""ä½ æ˜¯{agent['family_name']}å®¶åº­çš„ä»£è¡¨ï¼Œä»·å€¼è§‚ä¸º{agent['value_type']}ã€‚

å½“å‰åå•†è¿›å±•ï¼šç¤¾åŒºå·²ç¡®å®šåˆ†é…æ¡†æ¶ï¼ˆ{framework['strategy']['name']}ï¼‰ï¼Œç°åœ¨éœ€è¦å¯¹åˆæ­¥è®¡ç®—å‡ºçš„å…·ä½“åˆ†é…æ•°å­—è¿›è¡Œè®¨è®ºã€‚

ä½ å®¶æƒ…å†µï¼š
- æˆå‘˜æ•°ï¼š{agent['members']}äºº
- åŠ³åŠ¨åŠ›ï¼š{agent['labor_force']}äºº
- ç”Ÿå­˜éœ€æ±‚ï¼š{survival_need:.1f}å•ä½ç²®é£Ÿ
- åˆæ­¥åˆ†é…ï¼š{allocated_amount:.1f}å•ä½ç²®é£Ÿ
- ç›ˆä½™/ç¼ºå£ï¼š{allocated_amount - survival_need:+.1f}å•ä½

å…¶ä»–å®¶åº­çš„åˆæ­¥åˆ†é…ï¼š
{other_allocations_str}

ç¤¾åŒºèµ„æºæ€»é‡ï¼š{self.total_grain:.1f}å•ä½

è¯·æ ¹æ®ä½ çš„ä»·å€¼è§‚è¯„ä¼°è¿™ä¸ªåˆæ­¥åˆ†é…æ–¹æ¡ˆï¼š
1. ä½ æ˜¯å¦æ¥å—è¿™ä¸ªåˆ†é…æ•°é‡ï¼Ÿï¼ˆç›´æ¥å›ç­”"æ¥å—"æˆ–"æœ‰å¼‚è®®"ï¼‰
2. å¦‚æœæœ‰å¼‚è®®ï¼Œç®€è¦è¯´æ˜åŸå› ï¼ˆä¸è¶…è¿‡50å­—ï¼‰
3. å¦‚æœæœ‰å¼‚è®®ï¼Œä½ å¸Œæœ›è°ƒæ•´åˆ°å¤šå°‘å•ä½ï¼Ÿï¼ˆç»™å‡ºå…·ä½“æ•°å­—ï¼‰

è¯·æŒ‰ä»¥ä¸‹æ ¼å¼å›ç­”ï¼š
æ€åº¦ï¼š[æ¥å—/æœ‰å¼‚è®®]
ç†ç”±ï¼š[ä½ çš„ç†ç”±]
æœŸæœ›æ•°é‡ï¼š[æ•°å­—]ï¼ˆå¦‚æœæ¥å—åˆ™å¡«å½“å‰æ•°é‡ï¼‰
"""
        
        model_name = "deepseek-v3"
        temperature = 0.8
        
        try:
            start_time = time.time()
            response = client.chat.completions.create(
                model=model_name,
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªå‚ä¸ç¤¾åŒºèµ„æºåå•†çš„å®¶åº­ä»£è¡¨ã€‚è¯·æ ¹æ®ä½ çš„ä»·å€¼è§‚å’Œå®¶åº­å®é™…æƒ…å†µï¼ŒçœŸå®åœ°è¡¨è¾¾ä½ å¯¹åˆ†é…æ–¹æ¡ˆçš„çœ‹æ³•ã€‚"},
                    {"role": "user", "content": prompt}
                ],
                temperature=temperature,
                max_tokens=300
            )
            duration = time.time() - start_time
            
            content = response.choices[0].message.content
            
            # è§£æå›å¤
            has_objection = "æœ‰å¼‚è®®" in content
            
            # æå–æœŸæœ›æ•°é‡
            expected_amount = allocated_amount  # é»˜è®¤å€¼
            amount_match = re.search(r'æœŸæœ›æ•°é‡[:ï¼š]\s*([\d.]+)', content)
            if amount_match:
                try:
                    expected_amount = float(amount_match.group(1))
                except:
                    pass
            
            # æå–ç†ç”±
            reason_match = re.search(r'ç†ç”±[:ï¼š]\s*(.+?)(?=\n|æœŸæœ›æ•°é‡|$)', content, re.DOTALL)
            reason = reason_match.group(1).strip() if reason_match else "æœªè¯´æ˜"
            
            # è®°å½•LLMäº¤äº’
            llm_logger = get_logger()
            if llm_logger:
                llm_logger.log_negotiation_call(
                    round_number=self.round_number,
                    stage="details-opinion",
                    agent=agent,
                    input_prompt=prompt,
                    raw_output=content,
                    model=model_name,
                    temperature=temperature,
                    duration=duration,
                    success=True,
                    processed_data={
                        "has_objection": has_objection,
                        "expected_amount": expected_amount,
                        "allocated_amount": allocated_amount
                    }
                )
            
            return {
                "has_objection": has_objection,
                "objection_reason": reason if has_objection else "",
                "expected_amount": expected_amount,
                "allocated_amount": allocated_amount,
                "raw_response": content
            }
            
        except Exception as e:
            print(f"  è·å–{agent['family_name']}å®¶æ„è§å¤±è´¥: {str(e)}")
            return {
                "has_objection": False,
                "objection_reason": "",
                "expected_amount": allocated_amount,
                "allocated_amount": allocated_amount,
                "raw_response": "è·å–å¤±è´¥"
            }
    
    def _negotiate_disputed_allocations(self, allocation: Dict[int, Dict[str, float]],
                                      opinions: Dict[int, Dict[str, Any]],
                                      framework: Dict[str, Any]) -> Dict[int, Dict[str, float]]:
        """åå•†æœ‰äº‰è®®çš„åˆ†é…"""
        
        # è¯†åˆ«å¼‚è®®è€…å’Œä»–ä»¬çš„è¯‰æ±‚
        disputed_agents = [(aid, op) for aid, op in opinions.items() if op.get("has_objection")]
        
        if not disputed_agents:
            return allocation
        
        # è®¡ç®—æ€»çš„è°ƒæ•´éœ€æ±‚
        total_adjustment_need = sum(
            op["expected_amount"] - op["allocated_amount"] 
            for _, op in disputed_agents
        )
        
        print(f"    æ€»è°ƒæ•´éœ€æ±‚ï¼š{total_adjustment_need:+.1f}å•ä½")
        
        # å¦‚æœæ€»éœ€æ±‚ä¸ºæ­£ï¼ˆè¦æ±‚å¢åŠ ï¼‰ï¼Œéœ€è¦ä»å…¶ä»–å®¶åº­è°ƒå‰‚
        if abs(total_adjustment_need) < 0.5:
            print("    è°ƒæ•´å¹…åº¦å¾ˆå°ï¼Œæ¥å—ç°æœ‰æ–¹æ¡ˆ")
            return allocation
        
        # è¿›è¡Œä¸€è½®è°ƒæ•´åå•†
        adjusted_allocation = self._mediate_allocation_adjustment(
            allocation, disputed_agents, total_adjustment_need, framework
        )
        
        return adjusted_allocation
    
    def _mediate_allocation_adjustment(self, allocation: Dict[int, Dict[str, float]],
                                     disputed_agents: List[Tuple[int, Dict[str, Any]]],
                                     total_need: float,
                                     framework: Dict[str, Any]) -> Dict[int, Dict[str, float]]:
        """è°ƒè§£åˆ†é…è°ƒæ•´"""
        
        adjusted = copy.deepcopy(allocation)
        
        # é™åˆ¶è°ƒæ•´å¹…åº¦ï¼šæœ€å¤šè°ƒæ•´10%çš„æ€»èµ„æº
        max_adjustment = self.total_grain * 0.1
        actual_adjustment = min(abs(total_need), max_adjustment)
        
        if total_need > 0:  # æœ‰äººè¦æ±‚å¢åŠ 
            # æ–¹æ¡ˆ1ï¼šä»æ»¡æ„è€…ä¸­åŒ€å‡ºä¸€éƒ¨åˆ†
            satisfied_agents = [agent for agent in self.agents 
                              if agent["id"] not in [aid for aid, _ in disputed_agents]]
            
            if satisfied_agents:
                # æŒ‰æ¯”ä¾‹ä»æ»¡æ„è€…å¤„è°ƒå‡º
                donors = []
                for agent in satisfied_agents:
                    aid = agent["id"]
                    current = sum(adjusted[aid].values())
                    survival = sum(self.survival_needs.get(aid, {}).values())
                    surplus = current - survival
                    if surplus > 1.0:  # æœ‰ä½™é‡æ‰èƒ½è°ƒå‡º
                        donors.append((aid, surplus))
                
                if donors:
                    total_available = sum(s for _, s in donors)
                    actual_transfer = min(actual_adjustment, total_available * 0.3)  # æœ€å¤šè½¬30%çš„ä½™é‡
                    
                    # ä»donorè°ƒå‡º
                    for aid, surplus in donors:
                        transfer_amount = (surplus / total_available) * actual_transfer
                        adjusted[aid]["grain"] -= transfer_amount
                    
                    # åˆ†ç»™å¼‚è®®è€…
                    for aid, opinion in disputed_agents:
                        requested_increase = opinion["expected_amount"] - opinion["allocated_amount"]
                        if requested_increase > 0:
                            share = (requested_increase / total_need) * actual_transfer
                            adjusted[aid]["grain"] += share
                    
                    print(f"    è°ƒè§£æ–¹æ¡ˆï¼šä»{len(donors)}ä¸ªä½™é‡å®¶åº­è°ƒå‡º{actual_transfer:.1f}å•ä½")
                    
                    # è®°å½•è°ƒè§£å†³ç­–
                    if self.logger:
                        self.logger.log_decision(
                            decision_type="allocation_mediation",
                            decision_content={
                                "transferred_amount": actual_transfer,
                                "donors": [aid for aid, _ in donors],
                                "recipients": [aid for aid, _ in disputed_agents]
                            },
                            supporters=[aid for aid, _ in donors],
                            opponents=[]
                        )
        
        return adjusted
    
    def _validate_and_optimize(self, allocation: Dict[int, Dict[str, float]]) -> Dict[int, Dict[str, float]]:
        """éªŒè¯å’Œä¼˜åŒ–åˆ†é…æ–¹æ¡ˆ"""
        
        # éªŒè¯æ€»é‡
        total_allocated = sum(sum(agent_alloc.values()) for agent_alloc in allocation.values())
        
        if abs(total_allocated - self.total_grain) > 0.01:
            # éœ€è¦è°ƒæ•´
            adjustment_factor = self.total_grain / total_allocated
            # è®°å½•å½’ä¸€åŒ–
            if self.logger:
                try:
                    self.logger.log_decision(
                        decision_type="normalization_applied",
                        decision_content={
                            "factor": adjustment_factor,
                            "before_total": total_allocated,
                            "after_total": self.total_grain
                        },
                        supporters=[agent["id"] for agent in self.agents],
                        opponents=[]
                    )
                except Exception:
                    pass
            for agent_id in allocation:
                for resource in allocation[agent_id]:
                    allocation[agent_id][resource] *= adjustment_factor
        
        return allocation

    def _integerize_allocation(self, allocation: Dict[int, Dict[str, float]], enforce_min_survival: bool = True) -> Dict[int, Dict[str, float]]:
        """å°†æœ€ç»ˆåˆ†é…æ•´æ•°åŒ–ï¼ˆæœ€å¤§ä½™æ•°æ³• + ç”Ÿå­˜ä¿åº•ï¼‰
        
        æ­¥éª¤ï¼š
        1) ä»¥æ¯æˆ·floorä¸ºåŸºå‡†ï¼›
        2) è‹¥å¯ç”¨ä¿åº•ï¼Œåˆ™å°†æ¯æˆ·åŸºå‡†æå‡åˆ°ceil(ç”Ÿå­˜éœ€æ±‚)ï¼›
        3) è®¡ç®—ç›®æ ‡æ€»é‡=å››èˆäº”å…¥å½“å‰æ€»é‡ï¼›
        4) è‹¥åŸºå‡†å’Œ<ç›®æ ‡ï¼ŒæŒ‰å°æ•°éƒ¨åˆ†ç”±å¤§åˆ°å°+1ï¼›è‹¥åŸºå‡†å’Œ>ç›®æ ‡ï¼ŒæŒ‰å°æ•°éƒ¨åˆ†ç”±å°åˆ°å¤§-1ï¼Œä½†ä¸ä½äºä¿åº•ã€‚
        """
        # åªå¤„ç† grain è¿™ä¸€ä¸ªèµ„æº
        agent_ids = [agent["id"] for agent in self.agents]
        real_values: Dict[int, float] = {aid: float(allocation.get(aid, {}).get("grain", 0.0)) for aid in agent_ids}
        fractional: Dict[int, float] = {}
        base: Dict[int, int] = {}
        min_need: Dict[int, int] = {}
        
        for aid in agent_ids:
            val = real_values.get(aid, 0.0)
            base[aid] = math.floor(val)
            fractional[aid] = val - base[aid]
            if enforce_min_survival:
                need = sum(self.survival_needs.get(aid, {}).values())
                min_need[aid] = int(math.ceil(need)) if need > 0 else 0
            else:
                min_need[aid] = 0
        
        # åº”ç”¨ä¿åº•
        for aid in agent_ids:
            if base[aid] < min_need[aid]:
                base[aid] = min_need[aid]
                fractional[aid] = 0.0
        
        current_sum = sum(real_values.values())
        target_total = int(round(current_sum))
        base_sum = sum(base.values())
        
        # å¦‚æœåŸºå‡†å’Œå°äºç›®æ ‡ï¼ŒæŒ‰å°æ•°éƒ¨åˆ†ä»å¤§åˆ°å°åŠ 1
        if base_sum < target_total:
            need = target_total - base_sum
            order = sorted(agent_ids, key=lambda a: fractional[a], reverse=True)
            i = 0
            while need > 0 and i < len(order):
                aid = order[i]
                base[aid] += 1
                need -= 1
                i += 1
        # å¦‚æœåŸºå‡†å’Œå¤§äºç›®æ ‡ï¼ŒæŒ‰å°æ•°éƒ¨åˆ†ä»å°åˆ°å¤§å‡1ï¼ˆä¸ä½äºä¿åº•ï¼‰
        elif base_sum > target_total:
            excess = base_sum - target_total
            order = sorted(agent_ids, key=lambda a: fractional[a])
            i = 0
            while excess > 0 and i < len(order):
                aid = order[i]
                if base[aid] > min_need[aid]:
                    base[aid] -= 1
                    excess -= 1
                i += 1
        
        # ç»„è£…æ–°allocation
        new_alloc: Dict[int, Dict[str, float]] = {aid: {"grain": float(base.get(aid, 0))} for aid in agent_ids}
        
        # æ—¥å¿—è®°å½•
        if self.logger:
            try:
                diff = {aid: base[aid] - int(round(real_values.get(aid, 0.0))) for aid in agent_ids}
                self.logger.log_decision(
                    decision_type="integerization_applied",
                    decision_content={
                        "method": "largest_remainder_with_min",
                        "before_total": current_sum,
                        "after_total": sum(base.values()),
                        "changes": diff
                    },
                    supporters=[aid for aid in agent_ids],
                    opponents=[]
                )
            except Exception:
                pass
        
        return new_alloc
    
    def _finalize_proposal(self, detailed_proposal: Dict[int, Dict[str, float]]) -> Dict[int, Dict[str, float]]:
        """é˜¶æ®µ4ï¼šæœ€ç»ˆç¡®è®¤å’Œå¾®è°ƒï¼ˆåŒ…å«LLMé©±åŠ¨çš„å¤šè½®ç¡®è®¤ï¼‰"""
        self.current_stage = "finalization"
        
        # å¼€å§‹é˜¶æ®µæ—¥å¿—
        if self.logger:
            try:
                self.logger.start_stage("finalization", [agent["id"] for agent in self.agents])
            except Exception:
                pass
        
        print("\n   ã€ç¬¬1è½®ç¡®è®¤ã€‘å¾æ±‚å„å®¶åº­æœ€ç»ˆæ„è§...")
        
        # ç¬¬ä¸€è½®åé¦ˆ
        first_feedback = self._collect_final_confirmation(detailed_proposal, round_num=1)
        
        # è®°å½•ç¬¬ä¸€è½®åé¦ˆ
        self._log_feedback(first_feedback, "ç¬¬1è½®ç¡®è®¤")
        
        current_proposal = detailed_proposal
        
        # ğŸ¯ å¦‚æœæœ‰ä¸æ»¡æ„è€…ï¼Œè¿›è¡Œç¬¬2è½®å¾®è°ƒåå•†
        unsatisfied = [aid for aid, fb in first_feedback.items() 
                      if fb.get("satisfaction_level", 3) < 3]
        
        if unsatisfied and len(unsatisfied) <= len(self.agents) // 2:  # å°‘æ•°äººä¸æ»¡æ„
            print(f"\n   å‘ç°{len(unsatisfied)}å®¶ä¸æ»¡æ„ï¼Œè¿›è¡Œç¬¬2è½®å¾®è°ƒåå•†...")
            
            # ğŸ¯ è®©ä¸æ»¡æ„è€…æå‡ºå…·ä½“è°ƒæ•´æ–¹æ¡ˆ
            adjustment_proposals = self._collect_adjustment_proposals(
                current_proposal, first_feedback, unsatisfied
            )
            
            # ğŸ¯ è®©å…¶ä»–å®¶åº­å¯¹è°ƒæ•´æ–¹æ¡ˆæŠ•ç¥¨
            if adjustment_proposals:
                print("\n   å…¶ä»–å®¶åº­å¯¹å¾®è°ƒæ–¹æ¡ˆè¿›è¡ŒæŠ•ç¥¨...")
                adjusted_proposal = self._vote_on_adjustments(
                    current_proposal, adjustment_proposals
                )
                
                # ç¬¬2è½®ç¡®è®¤
                print("\n   ã€ç¬¬2è½®ç¡®è®¤ã€‘å†æ¬¡å¾æ±‚æ„è§...")
                second_feedback = self._collect_final_confirmation(adjusted_proposal, round_num=2)
                self._log_feedback(second_feedback, "ç¬¬2è½®ç¡®è®¤")
                
                current_proposal = adjusted_proposal
            else:
                print("   æœªèƒ½å½¢æˆæœ‰æ•ˆè°ƒæ•´æ–¹æ¡ˆï¼Œç»´æŒåŸæ–¹æ¡ˆ")
        elif len(unsatisfied) > len(self.agents) // 2:  # å¤šæ•°äººä¸æ»¡æ„
            print(f"\n   âš ï¸ å¤šæ•°å®¶åº­ï¼ˆ{len(unsatisfied)}å®¶ï¼‰ä¸æ»¡æ„ï¼Œä½†å·²è¾¾åå•†è½®æ¬¡ä¸Šé™")
            print("   ç»´æŒå½“å‰æ–¹æ¡ˆå¹¶è®°å½•åˆ†æ­§")
            if self.logger:
                self.logger.log_conflict(
                    conflict_topic="æœ€ç»ˆæ–¹æ¡ˆåˆ†æ­§ä¸¥é‡",
                    conflicting_parties=unsatisfied,
                    conflict_description=f"å¤šæ•°å®¶åº­ä¸æ»¡æ„ï¼Œä½†åå•†æœªè¾¾æˆæ›´å¥½æ–¹æ¡ˆ"
                )
        else:
            print("   âœ“ å„å®¶åº­åŸºæœ¬æ»¡æ„ï¼Œæ— éœ€å¾®è°ƒ")
        
        # æ•´æ•°åŒ–ï¼ˆæœ€å¤§ä½™æ•°æ³• + ç”Ÿå­˜ä¿åº•ï¼‰
        try:
            integerized = self._integerize_allocation(current_proposal, enforce_min_survival=True)
            current_proposal = integerized
        except Exception:
            pass
        
        print("\n   âœ“ åˆ†é…æ–¹æ¡ˆæœ€ç»ˆç¡®å®šï¼")
        print("\n   æœ€ç»ˆåˆ†é…ç»“æœï¼š")
        for agent in self.agents:
            aid = agent["id"]
            amount = sum(current_proposal.get(aid, {}).values())
            print(f"    {agent['family_name']}å®¶ï¼š{amount:.0f}å•ä½")
        
        # ç»“æŸé˜¶æ®µæ—¥å¿—
        try:
            # ä½¿ç”¨æœ€åä¸€è½®çš„åé¦ˆè®¡ç®—å…±è¯†åº¦
            final_feedback = first_feedback if not unsatisfied or len(unsatisfied) > len(self.agents) // 2 else second_feedback
            levels = [fb.get("satisfaction_level", 0.0) for fb in final_feedback.values()]
            avg_level = sum(levels) / len(levels) if levels else 0.0
            self.final_average_satisfaction = avg_level
            ok_ratio = sum(1 for l in levels if l >= 3.0) / len(levels) if levels else 0.0
            if self.logger:
                self.logger.end_stage(
                    stage_outcome="æœ€ç»ˆç¡®è®¤å®Œæˆ",
                    consensus_level=ok_ratio
                )
        except Exception:
            pass
        
        return current_proposal
    
    def _collect_final_confirmation(self, proposal: Dict[int, Dict[str, float]], 
                                   round_num: int = 1) -> Dict[int, Dict[str, Any]]:
        """æ”¶é›†æœ€ç»ˆç¡®è®¤åé¦ˆï¼ˆLLMé©±åŠ¨ï¼‰"""
        feedback = {}
        
        for agent in self.agents:
            agent_id = agent["id"]
            agent_allocation = proposal.get(agent_id, {})
            total_allocation = sum(agent_allocation.values())
            survival_need = sum(self.survival_needs.get(agent_id, {}).values())
            
            # ä½¿ç”¨LLMè·å–æœ€ç»ˆç¡®è®¤æ„è§
            confirmation = self._get_final_confirmation_llm(
                agent, total_allocation, survival_need, proposal, round_num
            )
            
            feedback[agent_id] = confirmation
        
        return feedback
    
    def _get_final_confirmation_llm(self, agent: Dict[str, Any], allocated_amount: float,
                                   survival_need: float, all_allocations: Dict[int, Dict[str, float]],
                                   round_num: int) -> Dict[str, Any]:
        """ä½¿ç”¨LLMè·å–æœ€ç»ˆç¡®è®¤æ„è§"""
        
        # æ„å»ºå…¶ä»–å®¶åº­åˆ†é…æƒ…å†µ
        other_info = ""
        for other_agent in self.agents:
            if other_agent["id"] != agent["id"]:
                other_amount = sum(all_allocations.get(other_agent["id"], {}).values())
                other_info += f"- {other_agent['family_name']}å®¶ï¼š{other_amount:.0f}å•ä½\n"
        
        prompt = f"""ä½ æ˜¯{agent['family_name']}å®¶åº­çš„ä»£è¡¨ï¼Œä»·å€¼è§‚ä¸º{agent['value_type']}ã€‚

ç»è¿‡å¤šè½®åå•†ï¼Œç°åœ¨éœ€è¦å¯¹æœ€ç»ˆåˆ†é…æ–¹æ¡ˆè¿›è¡Œç¬¬{round_num}è½®ç¡®è®¤ã€‚

ä½ å®¶çš„æœ€ç»ˆåˆ†é…ï¼š
- è·å¾—èµ„æºï¼š{allocated_amount:.0f}å•ä½ç²®é£Ÿ
- ç”Ÿå­˜éœ€æ±‚ï¼š{survival_need:.0f}å•ä½
- ç›ˆä½™/ç¼ºå£ï¼š{allocated_amount - survival_need:+.0f}å•ä½

å…¶ä»–å®¶åº­çš„åˆ†é…ï¼š
{other_info}

è¯·æ ¹æ®ä½ çš„ä»·å€¼è§‚è¯„ä»·è¿™ä¸ªæœ€ç»ˆæ–¹æ¡ˆï¼š
1. ä½ çš„æ»¡æ„ç¨‹åº¦ï¼ˆ1-5åˆ†ï¼Œ1=éå¸¸ä¸æ»¡æ„ï¼Œ3=å¯ä»¥æ¥å—ï¼Œ5=éå¸¸æ»¡æ„ï¼‰
2. å¦‚æœæ»¡æ„åº¦ä½äº3åˆ†ï¼Œè¯·è¯´æ˜ä½ çš„ä¸»è¦é¡¾è™‘ï¼ˆä¸è¶…è¿‡30å­—ï¼‰
3. å¦‚æœæœ‰é¡¾è™‘ï¼Œä½ å¸Œæœ›å¦‚ä½•è°ƒæ•´ï¼Ÿï¼ˆç®€è¦è¯´æ˜ï¼‰

è¯·æŒ‰ä»¥ä¸‹æ ¼å¼å›ç­”ï¼š
æ»¡æ„åº¦ï¼š[1-5çš„æ•°å­—]
é¡¾è™‘ï¼š[ä½ çš„é¡¾è™‘æˆ–"æ— "]
è°ƒæ•´å»ºè®®ï¼š[ä½ çš„å»ºè®®æˆ–"æ— "]
"""
        
        model_name = "deepseek-v3"
        temperature = 0.8
        
        try:
            start_time = time.time()
            response = client.chat.completions.create(
                model=model_name,
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªå‚ä¸ç¤¾åŒºèµ„æºåå•†çš„å®¶åº­ä»£è¡¨ã€‚ç°åœ¨æ˜¯æœ€ç»ˆç¡®è®¤é˜¶æ®µï¼Œè¯·çœŸå®è¡¨è¾¾ä½ å¯¹æœ€ç»ˆæ–¹æ¡ˆçš„çœ‹æ³•ã€‚"},
                    {"role": "user", "content": prompt}
                ],
                temperature=temperature,
                max_tokens=250
            )
            duration = time.time() - start_time
            
            content = response.choices[0].message.content
            
            # è§£ææ»¡æ„åº¦
            satisfaction_level = 3.0  # é»˜è®¤å€¼
            satisfaction_match = re.search(r'æ»¡æ„åº¦[ï¼š:]\s*([1-5])', content)
            if satisfaction_match:
                try:
                    satisfaction_level = float(satisfaction_match.group(1))
                except:
                    pass
            
            # æå–é¡¾è™‘
            concern_match = re.search(r'é¡¾è™‘[ï¼š:]\s*(.+?)(?=\n|è°ƒæ•´å»ºè®®|$)', content, re.DOTALL)
            concern = concern_match.group(1).strip() if concern_match else ""
            has_concern = concern and concern != "æ— " and satisfaction_level < 3
            
            # æå–è°ƒæ•´å»ºè®®
            adjustment_match = re.search(r'è°ƒæ•´å»ºè®®[ï¼š:]\s*(.+?)$', content, re.DOTALL)
            adjustment_suggestion = adjustment_match.group(1).strip() if adjustment_match else ""
            
            # è®°å½•LLMäº¤äº’
            llm_logger = get_logger()
            if llm_logger:
                llm_logger.log_negotiation_call(
                    round_number=self.round_number,
                    stage=f"finalization-round{round_num}",
                    agent=agent,
                    input_prompt=prompt,
                    raw_output=content,
                    model=model_name,
                    temperature=temperature,
                    duration=duration,
                    success=True,
                    processed_data={
                        "satisfaction_level": satisfaction_level,
                        "has_concern": has_concern,
                        "concern": concern
                    }
                )
            
            return {
                "satisfaction_level": satisfaction_level,
                "has_concerns": has_concern,
                "concern": concern if has_concern else "",
                "adjustment_suggestion": adjustment_suggestion if has_concern else "",
                "raw_response": content
            }
            
        except Exception as e:
            print(f"  è·å–{agent['family_name']}å®¶ç¡®è®¤æ„è§å¤±è´¥: {str(e)}")
            # ä½¿ç”¨åŸºäºè§„åˆ™çš„fallback
            satisfaction = 3.0
            if allocated_amount >= survival_need * 1.1:
                satisfaction = 4.0
            elif allocated_amount < survival_need:
                satisfaction = 2.0
            
            return {
                "satisfaction_level": satisfaction,
                "has_concerns": satisfaction < 3,
                "concern": "åˆ†é…ä¸è¶³" if satisfaction < 3 else "",
                "adjustment_suggestion": "",
                "raw_response": "è·å–å¤±è´¥"
            }
    
    def _log_feedback(self, feedback: Dict[int, Dict[str, Any]], stage_name: str):
        """è®°å½•åé¦ˆåˆ°æ—¥å¿—"""
        if not self.logger:
            return
        
        for agent in self.agents:
            aid = agent["id"]
            fb = feedback.get(aid, {})
            self.logger.log_discussion_turn(
                speaker_id=aid,
                speaker_name=agent["family_name"],
                speaker_value_type=agent["value_type"],
                content=f"æ»¡æ„åº¦ï¼š{fb.get('satisfaction_level', 0)}, {fb.get('concern', 'æ— é¡¾è™‘')}",
                speech_type="final_confirmation",
                target_topic=stage_name
            )
    
    def _collect_adjustment_proposals(self, current_allocation: Dict[int, Dict[str, float]],
                                    feedback: Dict[int, Dict[str, Any]],
                                    unsatisfied_agents: List[int]) -> List[Dict[str, Any]]:
        """æ”¶é›†ä¸æ»¡æ„å®¶åº­çš„è°ƒæ•´ææ¡ˆï¼ˆLLMé©±åŠ¨ï¼‰"""
        
        proposals = []
        
        for agent_id in unsatisfied_agents:
            agent = next((a for a in self.agents if a["id"] == agent_id), None)
            if not agent:
                continue
            
            fb = feedback.get(agent_id, {})
            current_amount = sum(current_allocation.get(agent_id, {}).values())
            
            # ç®€åŒ–å¤„ç†ï¼šç›´æ¥ä»åé¦ˆä¸­æå–è°ƒæ•´å»ºè®®
            adjustment_text = fb.get("adjustment_suggestion", "")
            
            if adjustment_text and adjustment_text != "æ— ":
                # å°è¯•ä»å»ºè®®ä¸­æå–æœŸæœ›çš„è°ƒæ•´é‡
                # ä¾‹å¦‚ï¼š"å¸Œæœ›å¢åŠ 5å•ä½" æˆ– "è°ƒæ•´åˆ°30å•ä½"
                amount_match = re.search(r'(\d+)', adjustment_text)
                if amount_match:
                    requested_change = float(amount_match.group(1))
                    
                    # åˆ¤æ–­æ˜¯å¢é‡è¿˜æ˜¯ç›®æ ‡å€¼
                    if "å¢åŠ " in adjustment_text or "å¤š" in adjustment_text:
                        target_amount = current_amount + requested_change
                    else:
                        target_amount = requested_change
                    
                    # é™åˆ¶è°ƒæ•´å¹…åº¦ï¼ˆæœ€å¤šÂ±20%ï¼‰
                    max_change = current_amount * 0.2
                    target_amount = max(current_amount - max_change, 
                                      min(target_amount, current_amount + max_change))
                    
                    proposals.append({
                        "agent_id": agent_id,
                        "agent_name": agent["family_name"],
                        "current_amount": current_amount,
                        "target_amount": target_amount,
                        "reason": fb.get("concern", ""),
                        "adjustment_text": adjustment_text
                    })
                    
                    print(f"    {agent['family_name']}å®¶ææ¡ˆï¼š{current_amount:.0f} â†’ {target_amount:.0f}å•ä½")
        
        return proposals
    
    def _vote_on_adjustments(self, current_allocation: Dict[int, Dict[str, float]],
                           proposals: List[Dict[str, Any]]) -> Dict[int, Dict[str, float]]:
        """è®©å…¶ä»–å®¶åº­å¯¹è°ƒæ•´ææ¡ˆæŠ•ç¥¨ï¼ˆç®€åŒ–å¤„ç†ï¼‰"""
        
        if not proposals:
            return current_allocation
        
        adjusted = copy.deepcopy(current_allocation)
        
        # ç®€åŒ–æŠ•ç¥¨ï¼šå¦‚æœææ¡ˆæ€»éœ€æ±‚åˆç†ï¼Œåˆ™æŒ‰æ¯”ä¾‹æ»¡è¶³
        total_increase_needed = sum(
            max(0, p["target_amount"] - p["current_amount"]) 
            for p in proposals
        )
        
        # æ‰¾å‡ºå¯ä»¥è´¡çŒ®çš„å®¶åº­ï¼ˆé«˜äºå¹³å‡æ°´å¹³çš„ï¼‰
        avg_allocation = self.total_grain / len(self.agents)
        potential_donors = [
            (agent["id"], sum(adjusted[agent["id"]].values()) - avg_allocation)
            for agent in self.agents
            if agent["id"] not in [p["agent_id"] for p in proposals]
            and sum(adjusted[agent["id"]].values()) > avg_allocation * 1.1
        ]
        
        if not potential_donors:
            print("    æ— å¯è°ƒé…èµ„æºï¼Œç»´æŒåŸæ–¹æ¡ˆ")
            return current_allocation
        
        total_available = sum(surplus for _, surplus in potential_donors)
        actual_transfer = min(total_increase_needed, total_available * 0.5)  # æœ€å¤šè½¬50%çš„ä½™é‡
        
        if actual_transfer > 0.5:
            # ä»donorè°ƒå‡º
            for donor_id, surplus in potential_donors:
                transfer_out = (surplus / total_available) * actual_transfer
                adjusted[donor_id]["grain"] -= transfer_out
            
            # åˆ†ç»™ææ¡ˆè€…
            for proposal in proposals:
                increase_needed = max(0, proposal["target_amount"] - proposal["current_amount"])
                if increase_needed > 0:
                    share = (increase_needed / total_increase_needed) * actual_transfer
                    adjusted[proposal["agent_id"]]["grain"] += share
            
            print(f"    âœ“ è°ƒæ•´é€šè¿‡ï¼šè½¬ç§»{actual_transfer:.1f}å•ä½èµ„æº")
            
            # è®°å½•å†³ç­–
            if self.logger:
                self.logger.log_decision(
                    decision_type="adjustment_voted_approved",
                    decision_content={
                        "transferred_amount": actual_transfer,
                        "proposals": proposals,
                        "donors": [did for did, _ in potential_donors]
                    },
                    supporters=[did for did, _ in potential_donors],
                    opponents=[]
                )
        else:
            print("    è°ƒæ•´å¹…åº¦è¿‡å°ï¼Œç»´æŒåŸæ–¹æ¡ˆ")
        
        return adjusted
    
    def _create_fallback_proposal(self) -> Dict[int, Dict[str, float]]:
        """åˆ›å»ºå›é€€åˆ†é…æ–¹æ¡ˆï¼ˆç®€å•å¹³å‡åˆ†é…ï¼‰"""
        per_family = self.total_grain / len(self.agents)
        
        return {
            agent["id"]: {"grain": per_family}
            for agent in self.agents
        }
    
    def _create_negotiation_data(self, success: bool, method: str) -> Dict[str, Any]:
        """åˆ›å»ºåå•†è¿‡ç¨‹æ•°æ®"""
        return {
            "success": success,
            "method": method,
            "stages_completed": list(self.stage_results.keys()),
            "conversation_rounds": len(self.conversation_history),
            "consensus_items": len(self.consensus_items),
            "final_stage": self.current_stage,
            "stage_results": self.stage_results
        }


def collaborative_negotiation_distribution(
    total_resources: Dict[str, float],
    agents: List[Dict[str, Any]],
    survival_needs: Dict[int, Dict[str, float]],
    round_number: int = 1,
    previous_distribution: Dict[int, Dict[str, float]] = None,
    max_negotiation_rounds: int = 4,
    experiment_id: str = None
) -> Dict[int, Dict[str, float]]:
    """åä½œå¼åå•†åˆ†é…çš„ä¸»å…¥å£å‡½æ•°
    
    å‚æ•°:
        total_resources: æ€»èµ„æºå­—å…¸
        agents: ä»£ç†åˆ—è¡¨
        survival_needs: ç”Ÿå­˜éœ€æ±‚å­—å…¸
        round_number: å½“å‰è½®æ•°
        previous_distribution: ä¸Šä¸€è½®åˆ†é…ç»“æœï¼ˆæš‚æœªä½¿ç”¨ï¼‰
        max_negotiation_rounds: æœ€å¤§åå•†è½®æ•°ï¼ˆæš‚æœªä½¿ç”¨ï¼‰
        experiment_id: å®éªŒIDï¼Œç”¨äºç»Ÿä¸€æ‰€æœ‰è½®æ¬¡çš„æ—¥å¿—
        
    è¿”å›:
        æœ€ç»ˆåˆ†é…ç»“æœå­—å…¸
    """
    
    try:
        # åˆ›å»ºåå•†æœºåˆ¶å®ä¾‹
        negotiation = CollaborativeNegotiation(
            agents=agents,
            total_resources=total_resources,
            survival_needs=survival_needs,
            round_number=round_number,
            experiment_id=experiment_id
        )
        
        # è¿è¡Œåå•†æµç¨‹
        final_allocation, negotiation_data = negotiation.run_collaborative_negotiation()
        
        # æ‰“å°ç»“æœæ‘˜è¦
        print(f"\n åå•†ç»“æœæ‘˜è¦ï¼š")
        print(f"   æˆåŠŸå®Œæˆï¼š{negotiation_data['success']}")
        print(f"   æ–¹æ³•ï¼š{negotiation_data['method']}")
        print(f"   å®Œæˆé˜¶æ®µï¼š{negotiation_data['stages_completed']}")
        
        return final_allocation
        
    except Exception as e:
        print(f"\n åå•†åˆ†é…å¤±è´¥ï¼Œä½¿ç”¨å¹³å‡åˆ†é…ä½œä¸ºå›é€€æ–¹æ¡ˆ: {str(e)}")
        
        # å›é€€åˆ°å¹³å‡åˆ†é…
        num_families = len(agents)
        if num_families == 0:
            return {}
        
        per_family_amount = total_resources.get("grain", 0) / num_families
        
        return {
            agent["id"]: {"grain": per_family_amount}
            for agent in agents
        }
